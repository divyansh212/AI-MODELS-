{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6Bzj39utZkVpbLie+R6Pj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyansh212/AI-MODELS-/blob/main/Pytorch_P3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "83gDQcLBEXpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1611a3b9-28e2-4c2f-8638-1babb30f6bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1,Loss:3.316792925525477\n",
            "Epoch2,Loss:3.1918482267076174\n",
            "Epoch3,Loss:3.0660582846334314\n",
            "Epoch4,Loss:2.9315520292325288\n",
            "Epoch5,Loss:2.795700828470979\n",
            "Epoch6,Loss:2.6548775541734266\n",
            "Epoch7,Loss:2.5094359883076645\n",
            "Epoch8,Loss:2.361853824824858\n",
            "Epoch9,Loss:2.214165568790243\n",
            "Epoch10,Loss:2.0669568607777\n",
            "Epoch11,Loss:1.9190818685133182\n",
            "Epoch12,Loss:1.777547720516062\n",
            "Epoch13,Loss:1.636522007894576\n",
            "Epoch14,Loss:1.4954684076971843\n",
            "Epoch15,Loss:1.3655633530634963\n",
            "Epoch16,Loss:1.248396022484461\n",
            "Epoch17,Loss:1.1454469123803213\n",
            "Epoch18,Loss:1.0578150111183076\n",
            "Epoch19,Loss:0.985865320989042\n",
            "Epoch20,Loss:0.9289310714631162\n",
            "Epoch21,Loss:0.8852532711052078\n",
            "Epoch22,Loss:0.8522914752873978\n",
            "Epoch23,Loss:0.827330060184487\n",
            "Epoch24,Loss:0.8080368746821661\n",
            "Epoch25,Loss:0.7926920323478479\n",
            "Epoch26,Loss:0.7801320490160834\n",
            "Epoch27,Loss:0.769595948308234\n",
            "Epoch28,Loss:0.7605855555716571\n",
            "Epoch29,Loss:0.7527674860230668\n",
            "Epoch30,Loss:0.7459108630384021\n",
            "Epoch31,Loss:0.7398492639104555\n",
            "Epoch32,Loss:0.7344577558305034\n",
            "Epoch33,Loss:0.7296390152151787\n",
            "Epoch34,Loss:0.7253148424202172\n",
            "Epoch35,Loss:0.721420869185778\n",
            "Epoch36,Loss:0.7179031589248086\n",
            "Epoch37,Loss:0.7147159375450977\n",
            "Epoch38,Loss:0.7118200095708919\n",
            "Epoch39,Loss:0.7091816000209864\n",
            "Epoch40,Loss:0.7067714704352752\n",
            "Epoch41,Loss:0.7045642196890415\n",
            "Epoch42,Loss:0.702537715890273\n",
            "Epoch43,Loss:0.7006726260106108\n",
            "Epoch44,Loss:0.6989520215583647\n",
            "Epoch45,Loss:0.6973610453717831\n",
            "Epoch46,Loss:0.6958866286567529\n",
            "Epoch47,Loss:0.6945172499256617\n",
            "Epoch48,Loss:0.6932427291796804\n",
            "Epoch49,Loss:0.6920540518771463\n",
            "Epoch50,Loss:0.6909432181406757\n",
            "Epoch51,Loss:0.6899031133796224\n",
            "Epoch52,Loss:0.6889273970994336\n",
            "Epoch53,Loss:0.6880104071675173\n",
            "Epoch54,Loss:0.6871470772260388\n",
            "Epoch55,Loss:0.6863328652987344\n",
            "Epoch56,Loss:0.6855636919411369\n",
            "Epoch57,Loss:0.6848358865394792\n",
            "Epoch58,Loss:0.6841461405796377\n",
            "Epoch59,Loss:0.6834914668896407\n",
            "Epoch60,Loss:0.6828691640125626\n",
            "Epoch61,Loss:0.6822767849954751\n",
            "Epoch62,Loss:0.6817121099883591\n",
            "Epoch63,Loss:0.6811731221377931\n",
            "Epoch64,Loss:0.6806579863366093\n",
            "Epoch65,Loss:0.6801650304549486\n",
            "Epoch66,Loss:0.6796927287322158\n",
            "Epoch67,Loss:0.6792396870550587\n",
            "Epoch68,Loss:0.6788046298850151\n",
            "Epoch69,Loss:0.6783863886321094\n",
            "Epoch70,Loss:0.6779838912983679\n",
            "Epoch71,Loss:0.6775961532387791\n",
            "Epoch72,Loss:0.6772222689073245\n",
            "Epoch73,Loss:0.6768614044728806\n",
            "Epoch74,Loss:0.6765127912045382\n",
            "Epoch75,Loss:0.6761757195385387\n",
            "Epoch76,Loss:0.6758495337499548\n",
            "Epoch77,Loss:0.6755336271616649\n",
            "Epoch78,Loss:0.6752274378313451\n",
            "Epoch79,Loss:0.6749304446642941\n",
            "Epoch80,Loss:0.674642163906068\n",
            "Epoch81,Loss:0.6743621459742938\n",
            "Epoch82,Loss:0.6740899725937155\n",
            "Epoch83,Loss:0.6738252542026486\n",
            "Epoch84,Loss:0.673567627602621\n",
            "Epoch85,Loss:0.6733167538261423\n",
            "Epoch86,Loss:0.6730723162003359\n",
            "Epoch87,Loss:0.6728340185866124\n",
            "Epoch88,Loss:0.6726015837787326\n",
            "Epoch89,Loss:0.6723747520435234\n",
            "Epoch90,Loss:0.6721532797901869\n",
            "Epoch91,Loss:0.671936938355658\n",
            "Epoch92,Loss:0.6717255128947748\n",
            "Epoch93,Loss:0.6715188013652139\n",
            "Epoch94,Loss:0.6713166135981867\n",
            "Epoch95,Loss:0.6711187704468158\n",
            "Epoch96,Loss:0.6709251030049441\n",
            "Epoch97,Loss:0.670735451889866\n",
            "Epoch98,Loss:0.6705496665831191\n",
            "Epoch99,Loss:0.6703676048240681\n",
            "Epoch100,Loss:0.6701891320515342\n",
            "0.5789473652839661\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
        "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)\n",
        "#train test split\n",
        "x_train,x_test,y_train,y_test=train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.2)\n",
        "#scaling\n",
        "scaler=StandardScaler()\n",
        "x_train=scaler.fit_transform(x_train)\n",
        "x_test=scaler.transform(x_test)\n",
        "#Label Encoder\n",
        "encode=LabelEncoder()\n",
        "y_train=encode.fit_transform(y_train)\n",
        "y_test=encode.transform(y_test)\n",
        "#converting array(Numpy) to Tensors(pytorch)\n",
        "x_train_tensor=torch.from_numpy(x_train)\n",
        "x_test_tensor=torch.from_numpy(x_test)\n",
        "y_train_tensor=torch.from_numpy(y_train)\n",
        "y_test_tensor=torch.from_numpy(y_test)\n",
        "#Defining neural network\n",
        "class  NN():\n",
        "  def __init__(self,x):\n",
        "    self.weights=torch.rand(x.shape[1],1,dtype=torch.float64,requires_grad=True)\n",
        "    self.bias=torch.zeros(1,dtype=torch.float64,requires_grad=True)\n",
        "  def forward_pass(self,x):\n",
        "    z=torch.matmul(x,self.weights)+self.bias\n",
        "    y_pred=torch.sigmoid(z)\n",
        "    return y_pred\n",
        "  def loss_function(self,y_pred,y):\n",
        "    episolon=1e-7\n",
        "    y_pred=torch.clamp(y_pred,episolon,1-episolon)\n",
        "    loss=-(y*torch.log(y_pred)+(1-y)*torch.log(1-y_pred)).mean()\n",
        "    return loss\n",
        "\n",
        "\n",
        "learning_rate=0.1\n",
        "epochs=100\n",
        "model=NN(x_train_tensor)\n",
        "model.weights\n",
        "model.bias\n",
        "#forward pass\n",
        "for epoch in range(epochs):\n",
        "  y_pred=model.forward_pass(x_train_tensor)\n",
        "  #LOSS CALCULATIONS\n",
        "  loss=model.loss_function(y_pred,y_train_tensor)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  #parameter Update\n",
        "  with torch.no_grad():\n",
        "    model.weights-=learning_rate*model.weights.grad\n",
        "    model.bias-=learning_rate*model.bias.grad\n",
        "  #zeroes grad\n",
        "  model.weights.grad.zero_()\n",
        "  model.bias.grad.zero_()\n",
        "  print(f\"Epoch{epoch+1},Loss:{loss.item()}\")\n",
        "model.bias\n",
        "with torch.no_grad():\n",
        "  y_pred=model.forward_pass(x_test_tensor)\n",
        "  y_pred=(y_pred>0.977786543).float()\n",
        "  accuracy=(y_pred==y_test_tensor).float().mean()\n",
        "  print(accuracy.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training deep learning model**\n",
        "\n",
        "\n",
        "1.   Loop as per epochs\n",
        "2.   forward pass\n",
        "3.   loss calculation\n",
        "4.   Backward pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gyXrbN6idIYO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rcTXi7MIMYsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQxjYr_oMYds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}